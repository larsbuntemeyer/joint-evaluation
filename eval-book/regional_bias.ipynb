{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regional Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "from warnings import warn\n",
    "\n",
    "import cf_xarray as cfxr\n",
    "import cordex as cx\n",
    "import dask\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import regionmask\n",
    "import xarray as xr\n",
    "import xesmf as xe\n",
    "from dask.distributed import Client\n",
    "from evaltools import obs\n",
    "from evaltools.eval import regional_means\n",
    "from evaltools.obs import eobs_mapping\n",
    "from evaltools.source import get_source_collection, open_and_sort\n",
    "from evaltools.utils import short_iid\n",
    "\n",
    "dask.config.set(scheduler=\"single-threaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(dashboard_address=\"localhost:8000\", threads_per_worker=1)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertices = {\n",
    "    \"CMIP6\": (\"vertices_lon\", \"vertices_lat\"),\n",
    "    \"CMIP5\": (\"lon_vertices\", \"lat_vertices\"),\n",
    "}\n",
    "\n",
    "\n",
    "def add_bounds(ds, mip_era=\"CMIP6\"):\n",
    "    if \"longitude\" not in ds.cf.bounds and \"latitude\" not in ds.cf.bounds:\n",
    "        ds = cx.transform_bounds(ds, trg_dims=vertices[mip_era])\n",
    "        ds = ds.assign_coords(\n",
    "            lon_b=cfxr.bounds_to_vertices(\n",
    "                ds[vertices[mip_era][0]],\n",
    "                bounds_dim=\"vertices\",\n",
    "                order=\"counterclockwise\",\n",
    "            ),\n",
    "            lat_b=cfxr.bounds_to_vertices(\n",
    "                ds[vertices[mip_era][1]],\n",
    "                bounds_dim=\"vertices\",\n",
    "                order=\"counterclockwise\",\n",
    "            ),\n",
    "        )\n",
    "    return ds\n",
    "\n",
    "\n",
    "def mask_with_sftlf(ds, sftlf=None):\n",
    "    if sftlf is None and \"sftlf\" in ds:\n",
    "        sftlf = ds[\"sftlf\"]\n",
    "        for var in ds.data_vars:\n",
    "            if var != \"sftlf\":\n",
    "                ds[var] = ds[var].where(sftlf > 0)\n",
    "        ds[\"mask\"] = sftlf > 0\n",
    "    else:\n",
    "        source = [\n",
    "            ds.attrs[attr]\n",
    "            for attr in [\"source_id\", \"model_id\", \"source\"]\n",
    "            if attr in ds.attrs\n",
    "        ]\n",
    "        warn(f\"sftlf not found in dataset: {source[0]}\")\n",
    "    return ds\n",
    "\n",
    "\n",
    "def open_datasets(\n",
    "    variables,\n",
    "    frequency=\"mon\",\n",
    "    driving_source_id=\"ERA5\",\n",
    "    mask=True,\n",
    "    add_missing_bounds=False,\n",
    "    **kargs,\n",
    "):\n",
    "    catalog = get_source_collection(\n",
    "        variables, frequency, driving_source_id, add_fx=[\"areacella\", \"sftlf\"]\n",
    "    )\n",
    "    dsets = open_and_sort(\n",
    "        catalog, merge=merge, concat=False, time_range=kargs.get(\"time_range\", None)\n",
    "    )\n",
    "    if mask is True:\n",
    "        for ds in dsets.values():\n",
    "            mask_with_sftlf(ds)\n",
    "    if add_missing_bounds is True:\n",
    "        for dset_id, ds in dsets.items():\n",
    "            if driving_source_id == \"ERA5\":\n",
    "                dsets[dset_id] = add_bounds(ds, mip_era=\"CMIP6\")\n",
    "            elif driving_source_id == \"ECMWF-ERAINT\":\n",
    "                dsets[dset_id] = add_bounds(ds, mip_era=\"CMIP5\")\n",
    "    return dsets\n",
    "\n",
    "\n",
    "def create_cordex_grid(domain_id, mip_era=\"CMIP6\"):\n",
    "    grid = cx.domain(domain_id, bounds=True, mip_era=mip_era)\n",
    "    lon_b = cfxr.bounds_to_vertices(\n",
    "        grid[vertices[mip_era][0]], bounds_dim=\"vertices\", order=\"counterclockwise\"\n",
    "    )\n",
    "    lat_b = cfxr.bounds_to_vertices(\n",
    "        grid[vertices[mip_era][1]], bounds_dim=\"vertices\", order=\"counterclockwise\"\n",
    "    )\n",
    "    return grid.assign_coords(lon_b=lon_b, lat_b=lat_b)\n",
    "\n",
    "\n",
    "def create_regridder(source, target, method=\"bilinear\"):\n",
    "    regridder = xe.Regridder(source, target, method=method)\n",
    "    return regridder\n",
    "\n",
    "\n",
    "def regrid(ds, regridder):\n",
    "    ds_regrid = regridder(ds)\n",
    "    for var in ds.data_vars:\n",
    "        if var not in [\"mask\", \"sftlf\"]:\n",
    "            ds_regrid[var] = ds_regrid[var].where(ds_regrid[\"mask\"] > 0.0)\n",
    "    return ds_regrid\n",
    "\n",
    "\n",
    "def regrid_dsets(dsets, target_grid, method=\"bilinear\"):\n",
    "    for dset_id, ds in dsets.items():\n",
    "        try:\n",
    "            mapping = ds.cf[\"grid_mapping\"].grid_mapping_name\n",
    "        except Exception:\n",
    "            print(\"problmes with grid_mapping definition\")\n",
    "            continue\n",
    "        if mapping == \"rotated_latitude_longitude\":\n",
    "            dsets[dset_id] = ds.cx.rewrite_coords(coords=\"all\")\n",
    "        else:\n",
    "            print(f\"regridding {dset_id} with grid_mapping: {mapping}\")\n",
    "            regridder = create_regridder(ds, target_grid, method=method)\n",
    "            print(regridder)\n",
    "            dsets[dset_id] = regrid(ds, regridder)\n",
    "    return dsets\n",
    "\n",
    "\n",
    "def mask_invalid(ds, vars=None, threshold=0.1):\n",
    "    if isinstance(vars, str):\n",
    "        vars = [vars]\n",
    "    if vars is None:\n",
    "        var = list(ds.data_vars)\n",
    "    for var in vars:\n",
    "        var_nan = ds[var].isnull().sum(dim=\"time\") / ds.time.size\n",
    "        ds[var] = ds[var].where(var_nan < threshold)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_celsius_to_kelvin(ds, threshold=200):\n",
    "    \"\"\"\n",
    "    Converts all temperature variables in an xarray Dataset from degrees Celsius to Kelvin\n",
    "    based on the 'units' attribute, value magnitude, or 'standard_name' attribute.\n",
    "\n",
    "    Parameters:\n",
    "        ds (xarray.Dataset): The input dataset.\n",
    "        threshold (float): A heuristic threshold (default=200) to assume temperatures\n",
    "                           below this value might be in Celsius.\n",
    "\n",
    "    Returns:\n",
    "        xarray.Dataset: A new dataset with converted temperature values.\n",
    "    \"\"\"\n",
    "    ds = ds.copy()  # Avoid modifying the original dataset\n",
    "\n",
    "    for var in ds.data_vars:\n",
    "        units = ds[var].attrs.get(\"units\", \"\").lower()\n",
    "        standard_name = ds[var].attrs.get(\"standard_name\", \"\").lower()\n",
    "\n",
    "        # Check if units explicitly indicate Celsius\n",
    "        if units in [\"c\", \"°c\", \"celsius\", \"degc\"]:\n",
    "            ds[var] = ds[var] + 273.15\n",
    "            ds[var].attrs[\"units\"] = \"K\"\n",
    "            print(\"Convert celsius to kelvin\")\n",
    "\n",
    "        # If no unit attribute exists, check standard_name for temperature-related terms\n",
    "        elif standard_name in [\n",
    "            \"air_temperature\",\n",
    "            \"sea_surface_temperature\",\n",
    "            \"surface_temperature\",\n",
    "        ]:\n",
    "            data_vals = ds[var].values\n",
    "            if np.nanmax(data_vals) < threshold:  # Likely in °C\n",
    "                ds[var] = ds[var] + 273.15\n",
    "                ds[var].attrs[\"units\"] = \"K\"\n",
    "                print(\"Convert celsius to kelvin\")\n",
    "\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seasonal_mean(da):\n",
    "    \"\"\"Optimized function to calculate seasonal averages from time series of monthly means\n",
    "\n",
    "    based on: https://xarray.pydata.org/en/stable/examples/monthly-means.html\n",
    "    \"\"\"\n",
    "    # Get number od days for each month\n",
    "    month_length = da.time.dt.days_in_month\n",
    "    # Calculate the weights by grouping by 'time.season'.\n",
    "    weights = (\n",
    "        month_length.groupby(\"time.season\") / month_length.groupby(\"time.season\").sum()\n",
    "    )\n",
    "\n",
    "    # Test that the sum of the weights for each season is 1.0\n",
    "    # np.testing.assert_allclose(weights.groupby(\"time.season\").sum().values, np.ones(4))\n",
    "\n",
    "    # Calculate the weighted average\n",
    "    return (\n",
    "        (da * weights).groupby(\"time.season\").sum(dim=\"time\", skipna=True, min_count=1)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_equal_period(ds, period):\n",
    "    years_in_ds = np.unique(ds.time.dt.year.values)\n",
    "    expected_years = np.arange(int(period.start), int(period.stop) + 1)\n",
    "    return np.array_equal(years_in_ds, expected_years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_attrs_ = [\n",
    "    \"project_id\",\n",
    "    \"domain_id\",\n",
    "    \"institution_id\",\n",
    "    \"driving_source_id\",\n",
    "    \"driving_experiment_id\",\n",
    "    \"driving_variant_label\",\n",
    "    \"source_id\",\n",
    "    \"version_realization\",\n",
    "    \"frequency\",\n",
    "    \"variable_id\",\n",
    "    \"version\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "var_dic = {\n",
    "    \"tas\": {\n",
    "        \"variable\": \"tas\",\n",
    "        \"name\": \"Temperature BIAS [K]\",\n",
    "        \"diff\": \"abs\",\n",
    "        \"range\": [-4, 4],\n",
    "        \"aggr\": \"mean\",\n",
    "    },\n",
    "    \"pr\": {\n",
    "        \"variable\": \"pr\",\n",
    "        \"name\": \"Precipitation BIAS [%]\",\n",
    "        \"diff\": \"rel\",\n",
    "        \"range\": [-60, 180],\n",
    "        \"aggr\": \"mean\",\n",
    "    },\n",
    "    \"tas95\": {\n",
    "        \"variable\": \"tas\",\n",
    "        \"name\": \"Temperature 95%-P [K]\",\n",
    "        \"diff\": \"abs\",\n",
    "        \"range\": [-2, 10],\n",
    "        \"aggr\": \"P95\",\n",
    "    },\n",
    "    \"pr95\": {\n",
    "        \"variable\": \"pr\",\n",
    "        \"name\": \"Precipitation 95%-P [%]\",\n",
    "        \"diff\": \"rel\",\n",
    "        \"range\": [0, 400],\n",
    "        \"aggr\": \"P95\",\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameter papermill\n",
    "index = \"pr95\"\n",
    "frequency = \"mon\"\n",
    "domain = \"EUR-11\"\n",
    "regridding = \"bilinear\"\n",
    "period = slice(\"1989\", \"2008\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_figure_path = os.path.abspath(os.path.join(os.getcwd(), \"..\", \"plots\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "variable = var_dic[index][\"variable\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eur_colors = pd.read_csv(\"eurocordex_models.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prudence\n",
    "regions = regionmask.defined_regions.prudence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotated_grid = create_cordex_grid(\"EUR-11\", mip_era=\"CMIP5\")  # No matter CMIP5 or CMIP6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## eobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eobs = obs.eobs(variable, add_mask=False).sel(time=period)\n",
    "eobs_var = [key for key, value in eobs_mapping.items() if value == variable][0]\n",
    "eobs = mask_invalid(eobs, vars=eobs_var, threshold=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regridder = xe.Regridder(eobs, rotated_grid, method=regridding, unmapped_to_nan=True)\n",
    "eobs_on_rotated = regridder(eobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not check_equal_period(eobs_on_rotated, period):\n",
    "    print(f\"Temporal coverage of dataset does not match with {period}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eobs_seasmean = seasonal_mean(eobs_on_rotated[eobs_var].sel(time=period)).compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CMIP6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mip_era = \"CMIP6\"\n",
    "driving_source_id = \"ERA5\"\n",
    "# Define how to merge the files in xarray\n",
    "merge = [\"variable_id\", \"frequency\"]\n",
    "default_attrs = [d for d in default_attrs_ if d not in merge]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dsets = open_datasets(\n",
    "    [variable],\n",
    "    frequency=frequency,\n",
    "    driving_source_id=driving_source_id,\n",
    "    mask=True,\n",
    "    add_missing_bounds=False,\n",
    "    **{\"merge\": merge, \"time_range\": period},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dset in dsets.keys():\n",
    "    if not check_equal_period(dsets[dset], period):\n",
    "        print(f\"Temporal coverage of {dset} does not match with {period}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dset in dsets.keys():\n",
    "    dsets[dset] = convert_celsius_to_kelvin(dsets[dset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsets = regrid_dsets(dsets, rotated_grid, method=regridding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if var_dic[index][\"diff\"] == \"abs\":\n",
    "    diffs = {\n",
    "        dset_id: seasonal_mean(ds[[variable]].sel(time=period)).compute()\n",
    "        - (eobs_seasmean + 273.15)\n",
    "        for dset_id, ds in dsets.items()\n",
    "        if variable in ds.variables\n",
    "    }\n",
    "elif var_dic[index][\"diff\"] == \"rel\":\n",
    "    diffs = {\n",
    "        dset_id: 100\n",
    "        * (\n",
    "            seasonal_mean(ds[[variable]].sel(time=period)).compute() * 86400\n",
    "            - (eobs_seasmean)\n",
    "        )\n",
    "        / (eobs_seasmean)\n",
    "        for dset_id, ds in dsets.items()\n",
    "        if variable in ds.variables\n",
    "    }\n",
    "\n",
    "seasonal_bias = xr.concat(\n",
    "    list(diffs.values()),\n",
    "    dim=xr.DataArray(\n",
    "        list(\n",
    "            map(\n",
    "                lambda x: short_iid(x, [\"source_id\"], default_attrs=default_attrs),\n",
    "                diffs.keys(),\n",
    "            )\n",
    "        ),\n",
    "        dims=\"dset_id\",\n",
    "    ),\n",
    "    compat=\"override\",\n",
    "    coords=\"minimal\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dset_id_regions = regional_means(seasonal_bias, regions, aggr=var_dic[index][\"aggr\"])\n",
    "dset_id_regions.to_netcdf(\n",
    "    f\"{mip_era}-CORDEX_{index}_region_means_{period.start}-{period.stop}.nc\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CMIP5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mip_era = \"CMIP5\"\n",
    "driving_source_id = \"ECMWF-ERAINT\"\n",
    "# Define how to merge the files in xarray\n",
    "merge = [\"variable_id\", \"frequency\", \"driving_variant_label\", \"version\"]\n",
    "default_attrs = [d for d in default_attrs_ if d not in merge]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsets = open_datasets(\n",
    "    [variable],\n",
    "    frequency=frequency,\n",
    "    driving_source_id=driving_source_id,\n",
    "    mask=True,\n",
    "    add_missing_bounds=False,\n",
    "    **{\"merge\": merge, \"time_range\": period},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dset in dsets.keys():\n",
    "    if not check_equal_period(dsets[dset], period):\n",
    "        print(f\"Temporal coverage of {dset} does not match with {period}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dset in dsets.keys():\n",
    "    dsets[dset] = convert_celsius_to_kelvin(dsets[dset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsets = regrid_dsets(dsets, rotated_grid, method=regridding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if var_dic[index][\"diff\"] == \"abs\":\n",
    "    diffs = {\n",
    "        dset_id: seasonal_mean(ds[[variable]].sel(time=period)).compute()\n",
    "        - (eobs_seasmean + 273.15)\n",
    "        for dset_id, ds in dsets.items()\n",
    "        if variable in ds.variables\n",
    "    }\n",
    "elif var_dic[index][\"diff\"] == \"rel\":\n",
    "    diffs = {\n",
    "        dset_id: 100\n",
    "        * (\n",
    "            seasonal_mean(ds[[variable]].sel(time=period)).compute() * 86400\n",
    "            - (eobs_seasmean)\n",
    "        )\n",
    "        / (eobs_seasmean)\n",
    "        for dset_id, ds in dsets.items()\n",
    "        if variable in ds.variables\n",
    "    }\n",
    "\n",
    "seasonal_bias = xr.concat(\n",
    "    list(diffs.values()),\n",
    "    dim=xr.DataArray(\n",
    "        list(\n",
    "            map(\n",
    "                lambda x: short_iid(x, [\"source_id\"], default_attrs=default_attrs),\n",
    "                diffs.keys(),\n",
    "            )\n",
    "        ),\n",
    "        dims=\"dset_id\",\n",
    "    ),\n",
    "    compat=\"override\",\n",
    "    coords=\"minimal\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = seasonal_bias.isel(dset_id=1)\n",
    "weights = xr.ones_like(ds.lon)\n",
    "mask = regions.mask_3D(ds.lon, ds.lat, drop=False)\n",
    "result = ds.cf.weighted(mask * weights).mean(dim=(\"X\", \"Y\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_id_regions = regional_means(seasonal_bias, regions, aggr=var_dic[index][\"aggr\"])\n",
    "dset_id_regions.to_netcdf(\n",
    "    f\"{mip_era}-CORDEX_{index}_region_means_{period.start}-{period.stop}.nc\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load results for both CMIP5 and CMIP6 simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasons = [\"DJF\", \"MAM\", \"JJA\", \"SON\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_id_regions_CMIP6 = xr.open_dataset(\n",
    "    f\"CMIP6-CORDEX_{index}_region_means_{period.start}-{period.stop}.nc\"\n",
    ")\n",
    "dset_id_regions_CMIP5 = xr.open_dataset(\n",
    "    f\"CMIP5-CORDEX_{index}_region_means_{period.start}-{period.stop}.nc\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_CMIP6 = dset_id_regions_CMIP6.to_dataframe().reset_index()\n",
    "df_CMIP5 = dset_id_regions_CMIP5.to_dataframe().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.min(df_CMIP5[variable]), np.max(df_CMIP5[variable]))\n",
    "print(np.min(df_CMIP6[variable]), np.max(df_CMIP6[variable]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "regs = [\"EA\", \"IP\", \"ME\", \"SC\"]\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8), sharex=True, sharey=True)\n",
    "axes = axes.flatten()\n",
    "\n",
    "handles = []\n",
    "labels = []\n",
    "\n",
    "for i, region in enumerate(regs):\n",
    "    ax = axes[i]\n",
    "\n",
    "    df_CMIP6_region = df_CMIP6[df_CMIP6[\"abbrevs\"] == region]\n",
    "    df_CMIP5_region = df_CMIP5[df_CMIP5[\"abbrevs\"] == region]\n",
    "\n",
    "    df_CMIP6_region[\"season_num\"] = df_CMIP6_region[\"season\"].apply(\n",
    "        lambda x: seasons.index(x)\n",
    "    )\n",
    "    df_CMIP5_region[\"season_num\"] = df_CMIP5_region[\"season\"].apply(\n",
    "        lambda x: seasons.index(x)\n",
    "    )\n",
    "\n",
    "    df_CMIP6_region[\"season_shifted\"] = df_CMIP6_region[\"season_num\"] + 0.1\n",
    "    df_CMIP5_region[\"season_shifted\"] = df_CMIP5_region[\"season_num\"] - 0.1\n",
    "\n",
    "    # Create lists to store the bias values for calculating median\n",
    "    cmip6_biases = {season: [] for season in seasons}\n",
    "    cmip5_biases = {season: [] for season in seasons}\n",
    "\n",
    "    for idx, row in df_CMIP6_region.iterrows():\n",
    "        dset_id = row[\"dset_id\"]\n",
    "        color = eur_colors[\"color\"][eur_colors[\"model\"] == dset_id].values[0]\n",
    "        scatter = ax.scatter(\n",
    "            row[\"season_shifted\"],\n",
    "            row[variable],\n",
    "            color=color,\n",
    "            edgecolors=color,\n",
    "            marker=\"o\",\n",
    "            s=80,\n",
    "        )\n",
    "\n",
    "        # Collect bias values for median calculation\n",
    "        cmip6_biases[row[\"season\"]].append(abs(row[variable]))\n",
    "\n",
    "        if dset_id not in labels:\n",
    "            handles.append(scatter)\n",
    "            labels.append(dset_id)\n",
    "\n",
    "        parent = eur_colors[\"parent\"][eur_colors[\"model\"] == dset_id].values[0]\n",
    "        if not pd.isnull(parent):\n",
    "            row_cmip5 = df_CMIP5_region[df_CMIP5_region[\"dset_id\"] == parent]\n",
    "            if not row_cmip5.empty:\n",
    "                row_cmip5 = row_cmip5[row_cmip5[\"season\"] == row.season].iloc[0]\n",
    "                ax.plot(\n",
    "                    [row_cmip5[\"season_shifted\"], row[\"season_shifted\"]],\n",
    "                    [row_cmip5[variable], row[variable]],\n",
    "                    color=color,\n",
    "                    linestyle=\"-\",\n",
    "                    zorder=0,\n",
    "                )\n",
    "\n",
    "    for idx, row in df_CMIP5_region.iterrows():\n",
    "        dset_id = row[\"dset_id\"]\n",
    "        color = eur_colors[\"color\"][eur_colors[\"model\"] == dset_id].values[0]\n",
    "        scatter = ax.scatter(\n",
    "            row[\"season_shifted\"],\n",
    "            row[variable],\n",
    "            color=color,\n",
    "            edgecolors=color,\n",
    "            facecolor=\"none\",\n",
    "            marker=\"o\",\n",
    "            s=80,\n",
    "        )\n",
    "\n",
    "        # Collect bias values for median calculation\n",
    "        cmip5_biases[row[\"season\"]].append(abs(row[variable]))\n",
    "\n",
    "        if dset_id not in labels:\n",
    "            handles.append(scatter)\n",
    "            labels.append(dset_id)\n",
    "\n",
    "    axes[0].set_ylabel(var_dic[index][\"name\"])\n",
    "    axes[2].set_ylabel(var_dic[index][\"name\"])\n",
    "    # Add region label in the top-left corner of each subplot\n",
    "    ax.text(\n",
    "        0.05,\n",
    "        0.95,\n",
    "        region,\n",
    "        transform=ax.transAxes,\n",
    "        fontsize=12,\n",
    "        verticalalignment=\"top\",\n",
    "        horizontalalignment=\"left\",\n",
    "        color=\"black\",\n",
    "        weight=\"bold\",\n",
    "    )\n",
    "\n",
    "    ax.set_xticks([0, 1, 2, 3])  # Adjust tick positions according to the shift\n",
    "    ax.set_xticklabels(seasons)  # Set the names of the seasons as labels\n",
    "\n",
    "    ax.grid(True)\n",
    "    ax.axhline(0, color=\"black\", linestyle=\"--\")\n",
    "\n",
    "    if variable == \"pr\":\n",
    "        ax.fill_between([-0.5, 3.5], 0, 25, color=\"#cceeff\", alpha=0.5)\n",
    "\n",
    "    # Calculate and display the absolute median bias for each season for both CMIP5 and CMIP6\n",
    "    for j, season in enumerate(seasons):\n",
    "        cmip6_median = (\n",
    "            np.nanmedian(cmip6_biases[season]) if cmip6_biases[season] else np.nan\n",
    "        )\n",
    "        cmip5_median = (\n",
    "            np.nanmedian(cmip5_biases[season]) if cmip5_biases[season] else np.nan\n",
    "        )\n",
    "\n",
    "        # Add the absolute median bias text below the season labels\n",
    "        # ax.text(j - 0.1, -3.2, f'CMIP6: {cmip6_median:.2f}\\nCMIP5: {cmip5_median:.2f}',\n",
    "        #        fontsize=10, verticalalignment='top', horizontalalignment='center', color='black')\n",
    "        ax.text(\n",
    "            j,\n",
    "            var_dic[index][\"range\"][0] + 0.5,\n",
    "            f\"{cmip5_median:.1f}  {cmip6_median:.1f}\",\n",
    "            fontsize=10,\n",
    "            verticalalignment=\"top\",\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"black\",\n",
    "        )\n",
    "\n",
    "fig.legend(\n",
    "    handles,\n",
    "    labels,\n",
    "    loc=\"upper center\",\n",
    "    bbox_to_anchor=(0.5, -0.05),\n",
    "    ncol=5,\n",
    "    fontsize=10,\n",
    ")\n",
    "\n",
    "# plt.ylim([var_dic[index]['range'][0],\n",
    "#          var_dic[index]['range'][1]])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig(\n",
    "    f\"{save_figure_path}/CMIP6-CMIP5_regionsA_bias_{index}_{period.start}-{period.stop}.png\",\n",
    "    bbox_inches=\"tight\",\n",
    "    transparent=True,\n",
    "    pad_inches=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "regs = [\"AL\", \"BI\", \"FR\", \"MD\"]\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8), sharex=True, sharey=True)\n",
    "axes = axes.flatten()\n",
    "\n",
    "handles = []\n",
    "labels = []\n",
    "\n",
    "for i, region in enumerate(regs):\n",
    "    ax = axes[i]\n",
    "\n",
    "    df_CMIP6_region = df_CMIP6[df_CMIP6[\"abbrevs\"] == region]\n",
    "    df_CMIP5_region = df_CMIP5[df_CMIP5[\"abbrevs\"] == region]\n",
    "\n",
    "    df_CMIP6_region[\"season_num\"] = df_CMIP6_region[\"season\"].apply(\n",
    "        lambda x: seasons.index(x)\n",
    "    )\n",
    "    df_CMIP5_region[\"season_num\"] = df_CMIP5_region[\"season\"].apply(\n",
    "        lambda x: seasons.index(x)\n",
    "    )\n",
    "\n",
    "    df_CMIP6_region[\"season_shifted\"] = df_CMIP6_region[\"season_num\"] + 0.1\n",
    "    df_CMIP5_region[\"season_shifted\"] = df_CMIP5_region[\"season_num\"] - 0.1\n",
    "\n",
    "    # Create lists to store the bias values for calculating median\n",
    "    cmip6_biases = {season: [] for season in seasons}\n",
    "    cmip5_biases = {season: [] for season in seasons}\n",
    "\n",
    "    for idx, row in df_CMIP6_region.iterrows():\n",
    "        dset_id = row[\"dset_id\"]\n",
    "        color = eur_colors[\"color\"][eur_colors[\"model\"] == dset_id].values[0]\n",
    "        scatter = ax.scatter(\n",
    "            row[\"season_shifted\"],\n",
    "            row[variable],\n",
    "            color=color,\n",
    "            edgecolors=color,\n",
    "            marker=\"o\",\n",
    "            s=80,\n",
    "        )\n",
    "\n",
    "        # Collect bias values for median calculation\n",
    "        cmip6_biases[row[\"season\"]].append(abs(row[variable]))\n",
    "\n",
    "        if dset_id not in labels:\n",
    "            handles.append(scatter)\n",
    "            labels.append(dset_id)\n",
    "\n",
    "        parent = eur_colors[\"parent\"][eur_colors[\"model\"] == dset_id].values[0]\n",
    "        if not pd.isnull(parent):\n",
    "            row_cmip5 = df_CMIP5_region[df_CMIP5_region[\"dset_id\"] == parent]\n",
    "            if not row_cmip5.empty:\n",
    "                row_cmip5 = row_cmip5[row_cmip5[\"season\"] == row.season].iloc[0]\n",
    "                ax.plot(\n",
    "                    [row_cmip5[\"season_shifted\"], row[\"season_shifted\"]],\n",
    "                    [row_cmip5[variable], row[variable]],\n",
    "                    color=color,\n",
    "                    linestyle=\"-\",\n",
    "                    zorder=0,\n",
    "                )\n",
    "\n",
    "    for idx, row in df_CMIP5_region.iterrows():\n",
    "        dset_id = row[\"dset_id\"]\n",
    "        color = eur_colors[\"color\"][eur_colors[\"model\"] == dset_id].values[0]\n",
    "        scatter = ax.scatter(\n",
    "            row[\"season_shifted\"],\n",
    "            row[variable],\n",
    "            color=color,\n",
    "            edgecolors=color,\n",
    "            facecolor=\"none\",\n",
    "            marker=\"o\",\n",
    "            s=80,\n",
    "        )\n",
    "\n",
    "        # Collect bias values for median calculation\n",
    "        cmip5_biases[row[\"season\"]].append(abs(row[variable]))\n",
    "\n",
    "        if dset_id not in labels:\n",
    "            handles.append(scatter)\n",
    "            labels.append(dset_id)\n",
    "\n",
    "    axes[0].set_ylabel(var_dic[index][\"name\"])\n",
    "    axes[2].set_ylabel(var_dic[index][\"name\"])\n",
    "    # Add region label in the top-left corner of each subplot\n",
    "    ax.text(\n",
    "        0.05,\n",
    "        0.95,\n",
    "        region,\n",
    "        transform=ax.transAxes,\n",
    "        fontsize=12,\n",
    "        verticalalignment=\"top\",\n",
    "        horizontalalignment=\"left\",\n",
    "        color=\"black\",\n",
    "        weight=\"bold\",\n",
    "    )\n",
    "\n",
    "    ax.set_xticks([0, 1, 2, 3])  # Adjust tick positions according to the shift\n",
    "    ax.set_xticklabels(seasons)  # Set the names of the seasons as labels\n",
    "\n",
    "    ax.grid(True)\n",
    "    ax.axhline(0, color=\"black\", linestyle=\"--\")\n",
    "\n",
    "    if variable == \"pr\":\n",
    "        ax.fill_between([-0.5, 3.5], 0, 25, color=\"#cceeff\", alpha=0.5)\n",
    "\n",
    "    # Calculate and display the absolute median bias for each season for both CMIP5 and CMIP6\n",
    "    for j, season in enumerate(seasons):\n",
    "        cmip6_median = (\n",
    "            np.nanmedian(cmip6_biases[season]) if cmip6_biases[season] else np.nan\n",
    "        )\n",
    "        cmip5_median = (\n",
    "            np.nanmedian(cmip5_biases[season]) if cmip5_biases[season] else np.nan\n",
    "        )\n",
    "\n",
    "        # Add the absolute median bias text below the season labels\n",
    "        # ax.text(j - 0.1, -3.2, f'CMIP6: {cmip6_median:.2f}\\nCMIP5: {cmip5_median:.2f}',\n",
    "        #        fontsize=10, verticalalignment='top', horizontalalignment='center', color='black')\n",
    "        ax.text(\n",
    "            j,\n",
    "            var_dic[index][\"range\"][0] + 0.5,\n",
    "            f\"{cmip5_median:.1f}  {cmip6_median:.1f}\",\n",
    "            fontsize=10,\n",
    "            verticalalignment=\"top\",\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"black\",\n",
    "        )\n",
    "\n",
    "fig.legend(\n",
    "    handles,\n",
    "    labels,\n",
    "    loc=\"upper center\",\n",
    "    bbox_to_anchor=(0.5, -0.05),\n",
    "    ncol=5,\n",
    "    fontsize=10,\n",
    ")\n",
    "\n",
    "# plt.ylim([var_dic[index]['range'][0],\n",
    "#          var_dic[index]['range'][1]])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig(\n",
    "    f\"{save_figure_path}/CMIP6-CMIP5_regionsB_bias_{index}_{period.start}-{period.stop}.png\",\n",
    "    bbox_inches=\"tight\",\n",
    "    transparent=True,\n",
    "    pad_inches=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (eval-book)",
   "language": "python",
   "name": "eval-book"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
