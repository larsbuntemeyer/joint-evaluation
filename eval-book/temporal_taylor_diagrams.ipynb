{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Temporal Taylor Diagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dask.config.set at 0x7d0daf101390>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import dask\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import regionmask\n",
    "import xarray as xr\n",
    "import xesmf as xe\n",
    "from dask.distributed import Client\n",
    "from evaltools import obs\n",
    "from evaltools.obs import eobs_mapping\n",
    "from evaltools.utils import short_iid\n",
    "from tools import (\n",
    "    TaylorDiagram,\n",
    "    check_equal_period,\n",
    "    create_cordex_grid,\n",
    "    fix_360_longitudes,\n",
    "    height_temperature_correction,\n",
    "    load_obs,\n",
    "    mask_invalid,\n",
    "    open_datasets,\n",
    "    regional_mean,\n",
    "    regional_means,\n",
    "    regrid_dsets,\n",
    "    select_season,\n",
    "    standardize_unit,\n",
    "    var_dic,\n",
    "    variable_mapping,\n",
    ")\n",
    "\n",
    "dask.config.set(scheduler=\"single-threaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(dashboard_address=\"localhost:8000\", threads_per_worker=1)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_uniform_cftime(ds):\n",
    "    \"\"\"Asegura que las fechas en el Dataset tengan un tipo uniforme de cftime.\"\"\"\n",
    "    time_vals = ds.time.values\n",
    "    types = {type(t) for t in time_vals}\n",
    "\n",
    "    if len(types) > 1:\n",
    "        # Usamos el tipo del primer elemento para reconstruir todos\n",
    "        base_type = type(time_vals[0])\n",
    "        uniform_time = [\n",
    "            base_type(t.year, t.month, t.day, t.hour, t.minute, t.second)\n",
    "            for t in time_vals\n",
    "        ]\n",
    "        ds[\"time\"] = (\"time\", uniform_time)\n",
    "\n",
    "    return ds\n",
    "\n",
    "\n",
    "def compute_tcoiav(model_ds, reference_ds):\n",
    "    \"\"\"\n",
    "    Compute the Temporal Correlation of Interannual Variability (TCOIAV) between model and reference data.\n",
    "\n",
    "    The Temporal Correlation of Interannual Variability (TCOIAV) measures the correlation between the\n",
    "    interannual variability of spatially averaged annual or seasonal mean values of the model and reference\n",
    "    datasets for a selected subregion. It quantifies how well the model captures the year-to-year variations\n",
    "    observed in the reference data.\n",
    "\n",
    "    A higher positive TCOIAV value indicates that the model accurately captures the interannual variability\n",
    "    observed in the reference data, while a lower or negative TCOIAV value indicates that the model's\n",
    "    interannual variability deviates significantly from that of the reference data.\n",
    "\n",
    "    Parameters:\n",
    "    model_ds (xarray.DataArray): The model data with spatial dimensions.\n",
    "    reference_ds (xarray.DataArray): The reference data with spatial dimensions.\n",
    "\n",
    "    Returns:\n",
    "    float: The TCOIAV value.\n",
    "    \"\"\"\n",
    "    # Compute the annual or seasonal mean values\n",
    "    try:\n",
    "        model_mean = model_ds.groupby(\"time.year\").mean(\"time\")\n",
    "        reference_mean = reference_ds.groupby(\"time.year\").mean(\"time\")\n",
    "    except (TypeError, AttributeError, ValueError):\n",
    "        # Homogeneiza los tipos de tiempo si hay mezcla de cftime\n",
    "        model_ds = ensure_uniform_cftime(model_ds)\n",
    "        reference_ds = ensure_uniform_cftime(reference_ds)\n",
    "\n",
    "        model_mean = model_ds.groupby(\"time.year\").mean(\"time\")\n",
    "        reference_mean = reference_ds.groupby(\"time.year\").mean(\"time\")\n",
    "\n",
    "    if \"lon\" in reference_mean.coords:\n",
    "        # Spatially average these mean values over the subregion\n",
    "        model_mean = model_mean.mean(dim=[\"lat\", \"lon\"])\n",
    "        reference_mean = reference_mean.mean(dim=[\"lat\", \"lon\"])\n",
    "\n",
    "    # Compute the temporal correlation of interannual variability\n",
    "    tcoiav = xr.corr(model_mean, reference_mean, dim=\"year\")\n",
    "\n",
    "    return tcoiav\n",
    "\n",
    "\n",
    "# RIAV: ratio (model over reference) of temporal standard\n",
    "# deviations of interannual time series of spatially aver-\n",
    "# aged annual or seasonal mean values of a selected sub-\n",
    "# region.\n",
    "\n",
    "\n",
    "def compute_riav(model_ds, reference_ds):\n",
    "    \"\"\"\n",
    "    Compute the Ratio of Interannual Variability (RIAV) between model and reference data.\n",
    "\n",
    "    The Ratio of Interannual Variability (RIAV) is the ratio of the temporal standard deviations\n",
    "    of interannual time series of spatially averaged annual or seasonal mean values between the model\n",
    "    and reference datasets for a selected subregion. It quantifies the relative temporal variability\n",
    "    in the model data compared to the reference data.\n",
    "\n",
    "    An RIAV value greater than 1 indicates that the model data has higher temporal variability\n",
    "    than the reference data, while an RIAV value less than 1 indicates lower temporal variability\n",
    "    in the model data compared to the reference data.\n",
    "\n",
    "    Parameters:\n",
    "    model_ds (xarray.DataArray): The model data with spatial dimensions.\n",
    "    reference_ds (xarray.DataArray): The reference data with spatial dimensions.\n",
    "\n",
    "    Returns:\n",
    "    float: The RIAV value.\n",
    "    \"\"\"\n",
    "    # Compute the annual or seasonal mean values\n",
    "    try:\n",
    "        model_mean = model_ds.groupby(\"time.year\").mean(\"time\")\n",
    "        reference_mean = reference_ds.groupby(\"time.year\").mean(\"time\")\n",
    "    except (TypeError, AttributeError, ValueError):\n",
    "        # Homogeneiza los tipos de tiempo si hay mezcla de cftime\n",
    "        model_ds = ensure_uniform_cftime(model_ds)\n",
    "        reference_ds = ensure_uniform_cftime(reference_ds)\n",
    "\n",
    "        model_mean = model_ds.groupby(\"time.year\").mean(\"time\")\n",
    "        reference_mean = reference_ds.groupby(\"time.year\").mean(\"time\")\n",
    "\n",
    "    if \"lon\" in reference_mean.coords:\n",
    "        # Spatially average these mean values over the subregion\n",
    "        model_mean = model_mean.mean(dim=[\"lat\", \"lon\"])\n",
    "        reference_mean = reference_mean.mean(dim=[\"lat\", \"lon\"])\n",
    "\n",
    "    # Compute the temporal standard deviations of the interannual time series\n",
    "    model_std = model_mean.std(dim=\"year\")\n",
    "    reference_std = reference_mean.std(dim=\"year\")\n",
    "\n",
    "    # Compute the ratio of these standard deviations (RIAV)\n",
    "    riav = model_std / reference_std\n",
    "\n",
    "    return riav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameter papermill\n",
    "index = \"pr\"\n",
    "frequency = \"mon\"\n",
    "domain = \"EUR-11\"\n",
    "regridding = \"bilinear\"\n",
    "period_star = \"1991\"\n",
    "period_stop = \"2020\"\n",
    "reference_regions = \"PRUDENCE\"\n",
    "parent = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "period = slice(period_star, period_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results_path = os.path.abspath(\n",
    "    os.path.join(os.getcwd(), \"..\", \"intermediate-results\")\n",
    ")\n",
    "save_figure_path = os.path.abspath(os.path.join(os.getcwd(), \"..\", \"plots\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "variable = var_dic[index][\"variable\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "eur_colors = pd.read_csv(\"eurocordex_models.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prudence\n",
    "regions = regionmask.defined_regions.prudence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotated_grid = create_cordex_grid(\"EUR-11\")  # No matter CMIP5 or CMIP6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E-OBS is used as the reference dataset for all the analysis\n",
    "It is used to calculate bias not only respect to CORDEX, but also in comparison wit other reanalyses and observational dataset, to assess the uncertaintly of the observational dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load, regrid and calculate seasonal means\n",
    "eobs_var = [key for key, value in eobs_mapping.items() if value == variable][0]\n",
    "eobs = obs.eobs(variables=eobs_var, add_mask=False).sel(time=period)\n",
    "eobs = mask_invalid(eobs, vars=eobs_var, threshold=0.1)\n",
    "eobs = standardize_unit(eobs, variable)\n",
    "# eobs = load_eobs(add_mask=False, to_cf=False, variable = variable)\n",
    "# unmapped_to_nan, see https://github.com/pangeo-data/xESMF/issues/56\n",
    "regridder = xe.Regridder(eobs, rotated_grid, method=regridding, unmapped_to_nan=True)\n",
    "ref_on_rotated = regridder(eobs)\n",
    "if not check_equal_period(ref_on_rotated, period):\n",
    "    print(f\"Temporal coverage of dataset does not match with {period}\")\n",
    "ref_regions = regional_mean(\n",
    "    ref_on_rotated[eobs_var], regions, aggr=var_dic[index][\"aggr\"]\n",
    ")\n",
    "ref_regions_seasons = select_season(ref_regions).compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CERRA and ERA5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsets = {}\n",
    "for dset in var_dic[variable][\"datasets\"]:\n",
    "    ds = load_obs(variable, dset, add_fx=True, mask=True)\n",
    "    ds = ds.sel(time=period).compute()\n",
    "    ds = fix_360_longitudes(ds, lonname=\"longitude\")\n",
    "    if not variable_mapping[dset][variable] == variable:\n",
    "        ds = ds.rename_vars({variable_mapping[dset][variable]: variable})\n",
    "    ds = standardize_unit(ds, variable)\n",
    "    dsets[dset] = ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dset in dsets.keys():\n",
    "    if not check_equal_period(dsets[dset], period):\n",
    "        print(f\"Temporal coverage of {dset} does not match with {period}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dset, ds in dsets.items():\n",
    "    regridder = xe.Regridder(ds, rotated_grid, method=regridding, unmapped_to_nan=True)\n",
    "    dsets[dset] = regridder(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if variable == \"tas\":\n",
    "    for dset in dsets:\n",
    "        h_c = height_temperature_correction(dsets[dset].orog, ref_on_rotated.elevation)\n",
    "        dsets[dset][\"tas\"] = dsets[dset].tas - h_c.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_regions = regional_means(dsets, regions, aggr=var_dic[index][\"aggr\"]).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_regions_seasons = select_season(obs_regions).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ds = obs_regions_seasons.copy()\n",
    "reference_ds = ref_regions_seasons.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffs = {}\n",
    "for dset_id in obs_regions_seasons.iid:\n",
    "    dset_id = str(dset_id.values)\n",
    "    model_id = obs_regions_seasons[variable].sel(iid=dset_id)\n",
    "    diffs[dset_id] = compute_tcoiav(model_id, ref_regions_seasons).compute()\n",
    "\n",
    "obs_tcoiav = xr.concat(\n",
    "    list(diffs.values()),\n",
    "    dim=xr.DataArray(\n",
    "        list(map(lambda x: x, diffs.keys())),\n",
    "        dims=\"dset_id\",\n",
    "    ),\n",
    "    compat=\"override\",\n",
    "    coords=\"minimal\",\n",
    ")\n",
    "\n",
    "diffs = {}\n",
    "for dset_id in obs_regions_seasons.iid:\n",
    "    dset_id = str(dset_id.values)\n",
    "    model_id = obs_regions_seasons[variable].sel(iid=dset_id)\n",
    "    diffs[dset_id] = compute_riav(model_id, ref_regions_seasons).compute()\n",
    "\n",
    "obs_riav = xr.concat(\n",
    "    list(diffs.values()),\n",
    "    dim=xr.DataArray(\n",
    "        list(map(lambda x: x, diffs.keys())),\n",
    "        dims=\"dset_id\",\n",
    "    ),\n",
    "    compat=\"override\",\n",
    "    coords=\"minimal\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CMIP6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "mip_era = \"CMIP6\"\n",
    "driving_source_id = \"ERA5\"\n",
    "# Define how to merge the files in xarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dsets = open_datasets(\n",
    "    [variable],\n",
    "    frequency=frequency,\n",
    "    driving_source_id=driving_source_id,\n",
    "    mask=True,\n",
    "    add_missing_bounds=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dset in dsets.keys():\n",
    "    dsets[dset] = dsets[dset].sel(time=period).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temporal coverage of CORDEX-CMIP6.EUR-12.ICTP.ERA5.evaluation.r1i1p1f1.RegCM5-0.v1-r1.mon.v20250415 does not match with slice('1991', '2020', None)\n"
     ]
    }
   ],
   "source": [
    "for dset in dsets.keys():\n",
    "    if not check_equal_period(dsets[dset], period):\n",
    "        print(f\"Temporal coverage of {dset} does not match with {period}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convert precipitation from kg/m/s² to mm/day.\n",
      "Convert precipitation from kg/m/s² to mm/day.\n",
      "Convert precipitation from kg/m/s² to mm/day.\n",
      "Convert precipitation from kg/m/s² to mm/day.\n",
      "Convert precipitation from kg/m/s² to mm/day.\n",
      "Convert precipitation from kg/m/s² to mm/day.\n",
      "Convert precipitation from kg/m/s² to mm/day.\n",
      "Convert precipitation from kg/m/s² to mm/day.\n",
      "Convert precipitation from kg/m/s² to mm/day.\n",
      "Convert precipitation from kg/m/s² to mm/day.\n",
      "Convert precipitation from kg/m/s² to mm/day.\n",
      "Convert precipitation from kg/m/s² to mm/day.\n",
      "Convert precipitation from kg/m/s² to mm/day.\n",
      "Convert precipitation from kg/m/s² to mm/day.\n"
     ]
    }
   ],
   "source": [
    "for dset in dsets.keys():\n",
    "    dsets[dset] = standardize_unit(dsets[dset], variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regridding CORDEX-CMIP6.EUR-12.RMIB-UGent.ERA5.evaluation.r1i1p1f1.ALARO1-SFX.v1-r1.mon.v20241009 with grid_mapping: lambert_conformal_conic\n",
      "xESMF Regridder \n",
      "Regridding algorithm:       bilinear \n",
      "Weight filename:            bilinear_483x483_412x424.nc \n",
      "Reuse pre-computed weights? False \n",
      "Input grid shape:           (483, 483) \n",
      "Output grid shape:          (412, 424) \n",
      "Periodic in longitude?      False\n",
      "regridding CORDEX-CMIP6.EUR-12.HCLIMcom-SMHI.ERA5.evaluation.r1i1p1f1.HCLIM43-ALADIN.v1-r1.mon.v20241205 with grid_mapping: lambert_conformal_conic\n",
      "xESMF Regridder \n",
      "Regridding algorithm:       bilinear \n",
      "Weight filename:            bilinear_453x453_412x424.nc \n",
      "Reuse pre-computed weights? False \n",
      "Input grid shape:           (453, 453) \n",
      "Output grid shape:          (412, 424) \n",
      "Periodic in longitude?      False\n",
      "regridding CORDEX-CMIP6.EUR-12.CESAM-UA.ERA5.evaluation.r1i1p1f1.WRF451Q.v1-r2.mon.v20250630 with grid_mapping: rotated_latitude_longitude\n",
      "xESMF Regridder \n",
      "Regridding algorithm:       bilinear \n",
      "Weight filename:            bilinear_412x424_412x424.nc \n",
      "Reuse pre-computed weights? False \n",
      "Input grid shape:           (412, 424) \n",
      "Output grid shape:          (412, 424) \n",
      "Periodic in longitude?      False\n",
      "regridding CORDEX-CMIP6.EUR-12.CNRM-MF.ERA5.evaluation.r1i1p1f1.CNRM-ALADIN64E1.v1-r1.mon.v20250505 with grid_mapping: lambert_conformal_conic\n",
      "xESMF Regridder \n",
      "Regridding algorithm:       bilinear \n",
      "Weight filename:            bilinear_453x453_412x424.nc \n",
      "Reuse pre-computed weights? False \n",
      "Input grid shape:           (453, 453) \n",
      "Output grid shape:          (412, 424) \n",
      "Periodic in longitude?      False\n",
      "regridding CORDEX-CMIP6.EUR-12.ICTP.ERA5.evaluation.r1i1p1f1.RegCM5-0.v1-r1.mon.v20250415 with grid_mapping: rotated_latitude_longitude\n",
      "xESMF Regridder \n",
      "Regridding algorithm:       bilinear \n",
      "Weight filename:            bilinear_412x424_412x424.nc \n",
      "Reuse pre-computed weights? False \n",
      "Input grid shape:           (412, 424) \n",
      "Output grid shape:          (412, 424) \n",
      "Periodic in longitude?      False\n"
     ]
    }
   ],
   "source": [
    "rotated_grid = create_cordex_grid(domain)\n",
    "dsets = regrid_dsets(dsets, rotated_grid, method=regridding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "if variable == \"tas\":\n",
    "    for dset in dsets:\n",
    "        h_c = height_temperature_correction(dsets[dset].orog, ref_on_rotated.elevation)\n",
    "        dsets[dset][\"tas\"] = dsets[dset].tas - h_c.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_id_regions = regional_means(dsets, regions, aggr=var_dic[index][\"aggr\"]).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_id_regions_seasons = select_season(dset_id_regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "diffs = {}\n",
    "for dset_id in dset_id_regions_seasons.iid:\n",
    "    print(str(dset_id.values))\n",
    "    dset_id = str(dset_id.values)\n",
    "    model_id = dset_id_regions_seasons[variable].sel(iid=dset_id)\n",
    "    diffs[dset_id] = compute_tcoiav(model_id, ref_regions_seasons).compute()\n",
    "\n",
    "dset_id_tcoiav = xr.concat(\n",
    "    list(diffs.values()),\n",
    "    dim=xr.DataArray(\n",
    "        list(map(lambda x: short_iid(x, [\"source_id\", \"version_realization\"], delimiter=\"_\"), diffs.keys())),\n",
    "        dims=\"dset_id\",\n",
    "    ),\n",
    "    compat=\"override\",\n",
    "    coords=\"minimal\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "diffs = {}\n",
    "for dset_id in dset_id_regions_seasons.iid:\n",
    "    dset_id = str(dset_id.values)\n",
    "    print(dset_id)\n",
    "    model_id = dset_id_regions_seasons[variable].sel(iid=dset_id)\n",
    "    diffs[dset_id] = compute_riav(model_id, ref_regions_seasons).compute()\n",
    "\n",
    "dset_id_riav = xr.concat(\n",
    "    list(diffs.values()),\n",
    "    dim=xr.DataArray(\n",
    "        list(map(lambda x: short_iid(x, [\"source_id\", \"version_realization\"], delimiter=\"_\"), diffs.keys())),\n",
    "        dims=\"dset_id\",\n",
    "    ),\n",
    "    compat=\"override\",\n",
    "    coords=\"minimal\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_id_tcoiav.to_netcdf(\n",
    "    f\"{save_results_path}/{variable}_CMIP6_tcoiav_{period.start}-{period.stop}.nc\"\n",
    ")\n",
    "dset_id_riav.to_netcdf(\n",
    "    f\"{save_results_path}/{variable}_CMIP6_riav_{period.start}-{period.stop}.nc\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CMIP5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "mip_era = \"CMIP5\"\n",
    "driving_source_id = \"ERAINT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dsets = open_datasets(\n",
    "    [variable],\n",
    "    frequency=frequency,\n",
    "    driving_source_id=driving_source_id,\n",
    "    mask=True,\n",
    "    add_missing_bounds=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsets_day = open_datasets(\n",
    "    [variable],\n",
    "    frequency='day',\n",
    "    source_id = ['WRF381P', 'HIRHAM5', 'RegCM4-6'],\n",
    "    driving_source_id=driving_source_id,\n",
    "    mask=True,\n",
    "    add_missing_bounds=False,\n",
    ")\n",
    "static_vars = [\"orog\", \"sftlf\", \"areacella\", \"mask\"]\n",
    "## resample dset_day\n",
    "dsets_mon = {}\n",
    "for dset in dsets_day.keys():\n",
    "    dsets_copy = dsets_day[dset].copy()\n",
    "    ds_var_mon = dsets_copy[[variable]].resample(time=\"ME\").mean()\n",
    "    for var in static_vars:\n",
    "        if var in dsets_copy.variables:\n",
    "            ds_var_mon[var] = dsets_copy[var]\n",
    "    dsets_mon[dset.replace('.day.', '.mon.')] = ds_var_mon\n",
    "dsets = dsets | dsets_mon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dset in dsets.keys():\n",
    "    dsets[dset] = dsets[dset].sel(time=period).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dset in dsets.keys():\n",
    "    if not check_equal_period(dsets[dset], period):\n",
    "        print(f\"Temporal coverage of {dset} does not match with {period}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dset in dsets.keys():\n",
    "    dsets[dset] = standardize_unit(dsets[dset], variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotated_grid = create_cordex_grid(domain)\n",
    "dsets = regrid_dsets(dsets, rotated_grid, method=regridding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "if variable == \"tas\":\n",
    "    for dset in dsets:\n",
    "        h_c = height_temperature_correction(dsets[dset].orog, ref_on_rotated.elevation)\n",
    "        dsets[dset][\"tas\"] = dsets[dset].tas - h_c.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_id_regions = regional_means(dsets, regions, aggr=var_dic[index][\"aggr\"]).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_id_regions_seasons = select_season(dset_id_regions).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "diffs = {}\n",
    "for dset_id in dset_id_regions_seasons.iid:\n",
    "    dset_id = str(dset_id.values)\n",
    "    print(dset_id)\n",
    "    model_id = dset_id_regions_seasons[variable].sel(iid=dset_id)\n",
    "    diffs[dset_id] = compute_tcoiav(model_id, ref_regions_seasons).compute()\n",
    "\n",
    "dset_id_tcoiav = xr.concat(\n",
    "    list(diffs.values()),\n",
    "    dim=xr.DataArray(\n",
    "        list(map(lambda x: short_iid(x, [\"source_id\", \"version_realization\"], delimiter=\"_\"), diffs.keys())),\n",
    "        dims=\"dset_id\",\n",
    "    ),\n",
    "    compat=\"override\",\n",
    "    coords=\"minimal\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "diffs = {}\n",
    "for dset_id in dset_id_regions_seasons.iid:\n",
    "    dset_id = str(dset_id.values)\n",
    "    print(dset_id)\n",
    "    model_id = dset_id_regions_seasons[variable].sel(iid=dset_id)\n",
    "    diffs[dset_id] = compute_riav(model_id, ref_regions_seasons).compute()\n",
    "\n",
    "dset_id_riav = xr.concat(\n",
    "    list(diffs.values()),\n",
    "    dim=xr.DataArray(\n",
    "        list(map(lambda x: short_iid(x, [\"source_id\", \"version_realization\"], delimiter=\"_\"), diffs.keys())),\n",
    "        dims=\"dset_id\",\n",
    "    ),\n",
    "    compat=\"override\",\n",
    "    coords=\"minimal\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_id_tcoiav.to_netcdf(\n",
    "    f\"{save_results_path}/{variable}_CMIP5_tcoiav_{period.start}-{period.stop}.nc\"\n",
    ")\n",
    "dset_id_riav.to_netcdf(\n",
    "    f\"{save_results_path}/{variable}_CMIP5_riav_{period.start}-{period.stop}.nc\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load results for both CMIP5 and CMIP6 simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dset_id_tcoiav_CMIP6 = xr.open_dataset(\n",
    "    f\"{save_results_path}/{variable}_CMIP6_tcoiav_{period.start}-{period.stop}.nc\"\n",
    ")\n",
    "dset_id_riav_CMIP6 = xr.open_dataset(\n",
    "    f\"{save_results_path}/{variable}_CMIP6_riav_{period.start}-{period.stop}.nc\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "CMIP6_coord = xr.DataArray(\n",
    "    np.full(len(dset_id_tcoiav_CMIP6[\"dset_id\"]), \"CMIP6\"),\n",
    "    dims=\"dset_id\",\n",
    "    coords={\"dset_id\": dset_id_tcoiav_CMIP6[\"dset_id\"]},\n",
    "    name=\"mip_era\",\n",
    ")\n",
    "dset_id_tcoiav_CMIP6 = dset_id_tcoiav_CMIP6.assign_coords(mip_era=CMIP6_coord)\n",
    "dset_id_riav_CMIP6 = dset_id_riav_CMIP6.assign_coords(mip_era=CMIP6_coord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_id_tcoiav_CMIP5 = xr.open_dataset(\n",
    "    f\"{save_results_path}/{variable}_CMIP5_tcoiav_{period.start}-{period.stop}.nc\"\n",
    ")\n",
    "dset_id_riav_CMIP5 = xr.open_dataset(\n",
    "    f\"{save_results_path}/{variable}_CMIP5_riav_{period.start}-{period.stop}.nc\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "CMIP5_coord = xr.DataArray(\n",
    "    np.full(len(dset_id_tcoiav_CMIP5[\"dset_id\"]), \"CMIP5\"),\n",
    "    dims=\"dset_id\",\n",
    "    coords={\"dset_id\": dset_id_tcoiav_CMIP5[\"dset_id\"]},\n",
    "    name=\"mip_era\",\n",
    ")\n",
    "dset_id_tcoiav_CMIP5 = dset_id_tcoiav_CMIP5.assign_coords(mip_era=CMIP5_coord)\n",
    "dset_id_riav_CMIP5 = dset_id_riav_CMIP5.assign_coords(mip_era=CMIP5_coord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasons_marker = {\"winter\": \"o\", \"summer\": \"^\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_str = \"no-parent\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_model_version = np.array((eur_colors[\"model\"].astype(str) + \"_\" + eur_colors[\"model_version\"].astype(str)).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# Reference std\n",
    "stdref = 1\n",
    "\n",
    "regions = [\"EA\", \"IP\", \"ME\", \"SC\"]\n",
    "\n",
    "for n_r, region in enumerate(regions):\n",
    "    fig = plt.figure()\n",
    "\n",
    "    dia = TaylorDiagram(stdref, fig=fig, label=\"Reference\")\n",
    "    # dia.samplePoints[0].set_color('r')  # Mark reference point as a red star\n",
    "\n",
    "    for season, mark in seasons_marker.items():\n",
    "\n",
    "        if parent is True:\n",
    "            parent_str = \"parent\"\n",
    "\n",
    "            # cmip5\n",
    "            rho = dset_id_tcoiav_CMIP5.isel(\n",
    "                region=np.where(dset_id_tcoiav_CMIP5.abbrevs == region)[0],\n",
    "                season=np.where(dset_id_tcoiav_CMIP5.season == season)[0],\n",
    "            ).squeeze()\n",
    "            std = dset_id_riav_CMIP5.isel(\n",
    "                region=np.where(dset_id_riav_CMIP5.abbrevs == region)[0],\n",
    "                season=np.where(dset_id_riav_CMIP5.season == season)[0],\n",
    "            ).squeeze()\n",
    "            # Add models to Taylor diagram\n",
    "            for i, model in enumerate(dset_id_tcoiav_CMIP5.dset_id.data):\n",
    "                mip_era = eur_colors[\"mip_era\"][list_model_version == model].values\n",
    "                color = eur_colors[\"color\"][list_model_version == model].values[0]\n",
    "                dia.add_sample(\n",
    "                    std.sel(dset_id=model)[list(std.data_vars)[0]].item(),\n",
    "                    rho.sel(dset_id=model)[list(rho.data_vars)[0]].item(),\n",
    "                    marker=mark,\n",
    "                    ms=5,\n",
    "                    ls=\"\",\n",
    "                    mfc=\"none\",\n",
    "                    mec=color,\n",
    "                    label=f\"{model}_{season}\",\n",
    "                )\n",
    "\n",
    "        # cmip6\n",
    "        rho = dset_id_tcoiav_CMIP6.isel(\n",
    "            region=np.where(dset_id_tcoiav_CMIP6.abbrevs == region)[0],\n",
    "            season=np.where(dset_id_tcoiav_CMIP6.season == season)[0],\n",
    "        ).squeeze()\n",
    "        std = dset_id_riav_CMIP6.isel(\n",
    "            region=np.where(dset_id_riav_CMIP6.abbrevs == region)[0],\n",
    "            season=np.where(dset_id_riav_CMIP6.season == season)[0],\n",
    "        ).squeeze()\n",
    "        # Add models to Taylor diagram\n",
    "        for i, model in enumerate(dset_id_tcoiav_CMIP6.dset_id.data):\n",
    "            mip_era = eur_colors[\"mip_era\"][list_model_version == model].values\n",
    "            color = eur_colors[\"color\"][list_model_version == model].values[0]\n",
    "            dia.add_sample(\n",
    "                std.sel(dset_id=model)[list(std.data_vars)[0]].item(),\n",
    "                rho.sel(dset_id=model)[list(rho.data_vars)[0]].item(),\n",
    "                marker=mark,\n",
    "                ms=5,\n",
    "                ls=\"\",\n",
    "                mfc=mcolors.to_rgba(color, 0.5),\n",
    "                mec=color,\n",
    "                label=f\"{model}_{season}\",\n",
    "            )\n",
    "\n",
    "        # obs\n",
    "        rho = obs_tcoiav.isel(\n",
    "            region=np.where(obs_tcoiav.abbrevs == region)[0],\n",
    "            season=np.where(obs_tcoiav.season == season)[0],\n",
    "        ).squeeze()\n",
    "        std = obs_riav.isel(\n",
    "            region=np.where(obs_riav.abbrevs == region)[0],\n",
    "            season=np.where(obs_riav.season == season)[0],\n",
    "        ).squeeze()\n",
    "        # Add models to Taylor diagram\n",
    "        for i, model in enumerate(obs_tcoiav.dset_id.data):\n",
    "            if \"era5\" in model:\n",
    "                color = \"magenta\"\n",
    "            else:\n",
    "                color = \"black\"\n",
    "\n",
    "            dia.add_sample(\n",
    "                std.sel(dset_id=model),\n",
    "                rho.sel(dset_id=model),\n",
    "                marker=mark,\n",
    "                ms=8,\n",
    "                ls=\"\",\n",
    "                mfc=\"none\",\n",
    "                mec=color,\n",
    "                label=f\"{model}_{season}\",\n",
    "            )\n",
    "\n",
    "    # Add correlation lines\n",
    "    dia.add_correlation_lines()\n",
    "\n",
    "    # Add RMS contours, and label them\n",
    "    contours = dia.add_contours(levels=2, colors=\"0.5\")  # 5 levels in grey\n",
    "    plt.clabel(contours, inline=1, fontsize=10, fmt=\"%.1f\")\n",
    "\n",
    "    if n_r == 1:\n",
    "        # Add a figure legend and title\n",
    "        fig.legend(\n",
    "            dia.samplePoints,\n",
    "            [p.get_label() for p in dia.samplePoints],\n",
    "            numpoints=1,\n",
    "            prop=dict(size=5),\n",
    "            loc=\"upper right\",\n",
    "        )\n",
    "\n",
    "    fig.text(0.25, 0.83, region, fontsize=12, fontweight=\"bold\", va=\"top\", ha=\"left\")\n",
    "\n",
    "    fig.savefig(\n",
    "        f\"taylor_{parent_str}_{region}_{period.start}-{period.stop}.png\", dpi=300\n",
    "    )\n",
    "    plt.close(fig)\n",
    "\n",
    "imgs = [\n",
    "    Image.open(f\"taylor_{parent_str}_{r}_{period.start}-{period.stop}.png\")\n",
    "    for r in regions\n",
    "]\n",
    "imgs = [img.crop(img.getbbox()) for img in imgs]\n",
    "\n",
    "w, h = imgs[0].size\n",
    "\n",
    "final_img = Image.new(\"RGB\", (2 * w, 2 * h), \"white\")\n",
    "\n",
    "final_img.paste(imgs[0], (0, 0))\n",
    "final_img.paste(imgs[1], (w, 0))\n",
    "final_img.paste(imgs[2], (0, h))\n",
    "final_img.paste(imgs[3], (w, h))\n",
    "\n",
    "final_img.save(\n",
    "    f\"{save_figure_path}/PRUDENCE_A_taylor_temporal_{parent_str}_{variable}_{period.start}-{period.stop}.png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# Reference std\n",
    "stdref = 1\n",
    "\n",
    "regions = [\"AL\", \"BI\", \"FR\", \"MD\"]\n",
    "\n",
    "for n_r, region in enumerate(regions):\n",
    "    fig = plt.figure()\n",
    "\n",
    "    dia = TaylorDiagram(stdref, fig=fig, label=\"Reference\")\n",
    "    # dia.samplePoints[0].set_color('r')  # Mark reference point as a red star\n",
    "\n",
    "    for season, mark in seasons_marker.items():\n",
    "\n",
    "        if parent is True:\n",
    "            parent_str = \"parent\"\n",
    "\n",
    "            # cmip5\n",
    "            rho = dset_id_tcoiav_CMIP5.isel(\n",
    "                region=np.where(dset_id_tcoiav_CMIP5.abbrevs == region)[0],\n",
    "                season=np.where(dset_id_tcoiav_CMIP5.season == season)[0],\n",
    "            ).squeeze()\n",
    "            std = dset_id_riav_CMIP5.isel(\n",
    "                region=np.where(dset_id_riav_CMIP5.abbrevs == region)[0],\n",
    "                season=np.where(dset_id_riav_CMIP5.season == season)[0],\n",
    "            ).squeeze()\n",
    "            # Add models to Taylor diagram\n",
    "            for i, model in enumerate(dset_id_tcoiav_CMIP5.dset_id.data):\n",
    "                mip_era = eur_colors[\"mip_era\"][list_model_version == model].values\n",
    "                color = eur_colors[\"color\"][list_model_version == model].values[0]\n",
    "                dia.add_sample(\n",
    "                    std.sel(dset_id=model)[list(std.data_vars)[0]].item(),\n",
    "                    rho.sel(dset_id=model)[list(rho.data_vars)[0]].item(),\n",
    "                    marker=mark,\n",
    "                    ms=5,\n",
    "                    ls=\"\",\n",
    "                    mfc=\"none\",\n",
    "                    mec=color,\n",
    "                    label=f\"{model}_{season}\",\n",
    "                )\n",
    "\n",
    "        # cmip6\n",
    "        rho = dset_id_tcoiav_CMIP6.isel(\n",
    "            region=np.where(dset_id_tcoiav_CMIP6.abbrevs == region)[0],\n",
    "            season=np.where(dset_id_tcoiav_CMIP6.season == season)[0],\n",
    "        ).squeeze()\n",
    "        std = dset_id_riav_CMIP6.isel(\n",
    "            region=np.where(dset_id_riav_CMIP6.abbrevs == region)[0],\n",
    "            season=np.where(dset_id_riav_CMIP6.season == season)[0],\n",
    "        ).squeeze()\n",
    "        # Add models to Taylor diagram\n",
    "        for i, model in enumerate(dset_id_tcoiav_CMIP6.dset_id.data):\n",
    "            mip_era = eur_colors[\"mip_era\"][list_model_version == model].values\n",
    "            color = eur_colors[\"color\"][list_model_version == model].values[0]\n",
    "            dia.add_sample(\n",
    "                std.sel(dset_id=model)[list(std.data_vars)[0]].item(),\n",
    "                rho.sel(dset_id=model)[list(rho.data_vars)[0]].item(),\n",
    "                marker=mark,\n",
    "                ms=5,\n",
    "                ls=\"\",\n",
    "                mfc=mcolors.to_rgba(color, 0.5),\n",
    "                mec=color,\n",
    "                label=f\"{model}_{season}\",\n",
    "            )\n",
    "\n",
    "        # obs\n",
    "        rho = obs_tcoiav.isel(\n",
    "            region=np.where(obs_tcoiav.abbrevs == region)[0],\n",
    "            season=np.where(obs_tcoiav.season == season)[0],\n",
    "        ).squeeze()\n",
    "        std = obs_riav.isel(\n",
    "            region=np.where(obs_riav.abbrevs == region)[0],\n",
    "            season=np.where(obs_riav.season == season)[0],\n",
    "        ).squeeze()\n",
    "        # Add models to Taylor diagram\n",
    "        for i, model in enumerate(obs_tcoiav.dset_id.data):\n",
    "            if \"era5\" in model:\n",
    "                color = \"magenta\"\n",
    "            else:\n",
    "                color = \"black\"\n",
    "\n",
    "            dia.add_sample(\n",
    "                std.sel(dset_id=model),\n",
    "                rho.sel(dset_id=model),\n",
    "                marker=mark,\n",
    "                ms=8,\n",
    "                ls=\"\",\n",
    "                mfc=\"none\",\n",
    "                mec=color,\n",
    "                label=f\"{model}_{season}\",\n",
    "            )\n",
    "\n",
    "    # Add correlation lines\n",
    "    dia.add_correlation_lines()\n",
    "\n",
    "    # Add RMS contours, and label them\n",
    "    contours = dia.add_contours(levels=2, colors=\"0.5\")  # 5 levels in grey\n",
    "    plt.clabel(contours, inline=1, fontsize=10, fmt=\"%.1f\")\n",
    "\n",
    "    if n_r == 1:\n",
    "        # Add a figure legend and title\n",
    "        fig.legend(\n",
    "            dia.samplePoints,\n",
    "            [p.get_label() for p in dia.samplePoints],\n",
    "            numpoints=1,\n",
    "            prop=dict(size=3.5),\n",
    "            loc=\"upper right\",\n",
    "        )\n",
    "\n",
    "    fig.text(0.25, 0.83, region, fontsize=12, fontweight=\"bold\", va=\"top\", ha=\"left\")\n",
    "\n",
    "    fig.savefig(\n",
    "        f\"taylor_{parent_str}_{region}_{period.start}-{period.stop}.png\", dpi=300\n",
    "    )\n",
    "    plt.close(fig)\n",
    "\n",
    "imgs = [\n",
    "    Image.open(f\"taylor_{parent_str}_{r}_{period.start}-{period.stop}.png\")\n",
    "    for r in regions\n",
    "]\n",
    "imgs = [img.crop(img.getbbox()) for img in imgs]\n",
    "\n",
    "w, h = imgs[0].size\n",
    "\n",
    "final_img = Image.new(\"RGB\", (2 * w, 2 * h), \"white\")\n",
    "\n",
    "final_img.paste(imgs[0], (0, 0))\n",
    "final_img.paste(imgs[1], (w, 0))\n",
    "final_img.paste(imgs[2], (0, h))\n",
    "final_img.paste(imgs[3], (w, h))\n",
    "\n",
    "final_img.save(\n",
    "    f\"{save_figure_path}/PRUDENCE_B_taylor_temporal_{parent_str}_{variable}_{period.start}-{period.stop}.png\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (evaltools)",
   "language": "python",
   "name": "evaltools"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
