{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EOBS seasonal means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import warn\n",
    "\n",
    "import cf_xarray as cfxr\n",
    "import cordex as cx\n",
    "import dask\n",
    "import xarray as xr\n",
    "import xesmf as xe\n",
    "from dask.distributed import Client\n",
    "from evaltools import obs\n",
    "from evaltools.source import get_source_collection, open_and_sort\n",
    "from evaltools.utils import short_iid\n",
    "\n",
    "dask.config.set(scheduler=\"single-threaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(dashboard_address=\"localhost:8787\", threads_per_worker=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_fx = [\"orog\", \"areacella\", \"sftlf\"]\n",
    "variable = \"tas\"\n",
    "\n",
    "\n",
    "def add_bounds(ds):\n",
    "    if \"longitude\" not in ds.cf.bounds and \"latitude\" not in ds.cf.bounds:\n",
    "        ds = cx.transform_bounds(ds, trg_dims=(\"vertices_lon\", \"vertices_lat\"))\n",
    "    lon_bounds = ds.cf.get_bounds(\"longitude\")\n",
    "    lat_bounds = ds.cf.get_bounds(\"latitude\")\n",
    "    bounds_dim = [dim for dim in lon_bounds.dims if dim not in ds.indexes][0]\n",
    "    # reshape bounds for xesmf\n",
    "    ds = ds.assign_coords(\n",
    "        lon_b=cfxr.bounds_to_vertices(\n",
    "            lon_bounds, bounds_dim=bounds_dim, order=\"counterclockwise\"\n",
    "        ),\n",
    "        lat_b=cfxr.bounds_to_vertices(\n",
    "            lat_bounds, bounds_dim=bounds_dim, order=\"counterclockwise\"\n",
    "        ),\n",
    "    )\n",
    "    return ds\n",
    "\n",
    "\n",
    "def mask_with_sftlf(ds, sftlf=None):\n",
    "    if sftlf is None and \"sftlf\" in ds:\n",
    "        sftlf = ds[\"sftlf\"]\n",
    "        for var in ds.data_vars:\n",
    "            if var != \"sftlf\":\n",
    "                ds[var] = ds[var].where(sftlf > 0)\n",
    "        ds[\"mask\"] = sftlf > 0\n",
    "    else:\n",
    "        warn(f\"sftlf not found in dataset: {ds.source_id}\")\n",
    "    return ds\n",
    "\n",
    "\n",
    "def open_datasets(\n",
    "    variables, frequency=\"mon\", mask=True, add_missing_bounds=True, **kwargs\n",
    "):\n",
    "    cat = get_source_collection(variables, frequency, add_fx=add_fx, **kwargs)\n",
    "    dsets = open_and_sort(cat, merge_fx=True, apply_fixes=True)\n",
    "    if mask is True:\n",
    "        for ds in dsets.values():\n",
    "            mask_with_sftlf(ds)\n",
    "    if add_missing_bounds is True:\n",
    "        for dset_id, ds in dsets.items():\n",
    "            dsets[dset_id] = add_bounds(ds)\n",
    "    return dsets\n",
    "\n",
    "\n",
    "def create_cordex_grid(domain_id):\n",
    "    grid = cx.domain(domain_id, bounds=True, mip_era=\"CMIP6\")\n",
    "    # grid[\"lon\"].attrs = {}\n",
    "    # grid[\"vertices_lat\"].attrs = {}\n",
    "    lon_b = cfxr.bounds_to_vertices(\n",
    "        grid.vertices_lon, bounds_dim=\"vertices\", order=\"counterclockwise\"\n",
    "    )\n",
    "    lat_b = cfxr.bounds_to_vertices(\n",
    "        grid.vertices_lat, bounds_dim=\"vertices\", order=\"counterclockwise\"\n",
    "    )\n",
    "    return grid.assign_coords(lon_b=lon_b, lat_b=lat_b)\n",
    "\n",
    "\n",
    "def create_regridder(source, target, method=\"bilinear\"):\n",
    "    regridder = xe.Regridder(source, target, method=method)\n",
    "    return regridder\n",
    "\n",
    "\n",
    "def regrid(ds, regridder, mask_after_regrid=True):\n",
    "    ds_regrid = regridder(ds)\n",
    "    if mask_after_regrid:\n",
    "        for var in ds.data_vars:\n",
    "            if var not in add_fx:\n",
    "                ds_regrid[var] = ds_regrid[var].where(ds_regrid[\"mask\"] > 0.0)\n",
    "    return ds_regrid\n",
    "\n",
    "\n",
    "def regrid_dsets(dsets, target_grid, method=\"bilinear\"):\n",
    "    for dset_id, ds in dsets.items():\n",
    "        print(dset_id)\n",
    "        mapping = ds.cf[\"grid_mapping\"].grid_mapping_name\n",
    "        if mapping == \"rotated_latitude_longitude\":\n",
    "            dsets[dset_id] = ds.cx.rewrite_coords(coords=\"all\")\n",
    "        else:\n",
    "            print(f\"regridding {dset_id} with grid_mapping: {mapping}\")\n",
    "            regridder = create_regridder(ds, target_grid, method=method)\n",
    "            print(regridder)\n",
    "            dsets[dset_id] = regrid(ds, regridder)\n",
    "    return dsets\n",
    "\n",
    "\n",
    "def mask_invalid(ds, vars=None, threshold=0.1):\n",
    "    if isinstance(vars, str):\n",
    "        vars = [vars]\n",
    "    if vars is None:\n",
    "        var = list(ds.data_vars)\n",
    "    for var in vars:\n",
    "        var_nan = ds[var].isnull().sum(dim=\"time\") / ds.time.size\n",
    "        ds[var] = ds[var].where(var_nan < threshold)\n",
    "    return ds\n",
    "\n",
    "\n",
    "def height_temperature_correction(model_elev, obs_elev):\n",
    "    \"\"\"\n",
    "    Height correction for temperature\n",
    "    \"\"\"\n",
    "    lapse_rate = 0.0065  # Â°C per meter\n",
    "    # Apply correction (adjust model temp to obs elevation)\n",
    "    return lapse_rate * (obs_elev - model_elev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsets = open_datasets(\n",
    "    variable,\n",
    "    frequency=\"mon\",\n",
    "    mip_era=\"CMIP6\",\n",
    "    add_missing_bounds=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotated_grid = create_cordex_grid(\"EUR-12\")\n",
    "dsets = regrid_dsets(dsets, rotated_grid, method=\"bilinear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "period = slice(\"1980\", \"2020\")\n",
    "\n",
    "eobs = obs.eobs(variables=\"tg\", add_mask=False).sel(time=period)\n",
    "eobs = mask_invalid(eobs, vars=\"tg\", threshold=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unmapped_to_nan, see https://github.com/pangeo-data/xESMF/issues/56\n",
    "regridder = xe.Regridder(eobs, rotated_grid, method=\"bilinear\", unmapped_to_nan=True)\n",
    "eobs_on_rotated = regridder(eobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seasonal_mean(da):\n",
    "    \"\"\"Optimized function to calculate seasonal averages from time series of monthly means\n",
    "\n",
    "    based on: https://xarray.pydata.org/en/stable/examples/monthly-means.html\n",
    "    \"\"\"\n",
    "    # Get number od days for each month\n",
    "    month_length = da.time.dt.days_in_month\n",
    "    # Calculate the weights by grouping by 'time.season'.\n",
    "    weights = (\n",
    "        month_length.groupby(\"time.season\") / month_length.groupby(\"time.season\").sum()\n",
    "    )\n",
    "\n",
    "    # Test that the sum of the weights for each season is 1.0\n",
    "    # np.testing.assert_allclose(weights.groupby(\"time.season\").sum().values, np.ones(4))\n",
    "\n",
    "    # Calculate the weighted average\n",
    "    return (\n",
    "        (da * weights).groupby(\"time.season\").sum(dim=\"time\", skipna=True, min_count=1)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "eobs_seasmean = seasonal_mean(eobs_on_rotated.tg.sel(time=period)).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "variable = \"tas\"\n",
    "\n",
    "bias = {\n",
    "    dset_id: (\n",
    "        seasonal_mean(ds[[variable]].sel(time=period)).compute()\n",
    "        + height_temperature_correction(ds.orog, eobs_on_rotated.elevation)\n",
    "        - (eobs_seasmean + 273.15)\n",
    "    )\n",
    "    for dset_id, ds in dsets.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasonal_bias = xr.concat(\n",
    "    list(bias.values()),\n",
    "    dim=xr.DataArray(\n",
    "        list(\n",
    "            map(\n",
    "                lambda x: short_iid(x, [\"institution_id\", \"source_id\"], delimiter=\"-\"),\n",
    "                bias.keys(),\n",
    "            )\n",
    "        ),\n",
    "        dims=\"dset_id\",\n",
    "    ),\n",
    "    compat=\"override\",\n",
    "    coords=\"minimal\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "seasonal_bias_ = seasonal_bias.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from cartopy import crs as ccrs\n",
    "from cartopy.mpl.ticker import LatitudeFormatter, LongitudeFormatter\n",
    "\n",
    "ds = seasonal_bias_\n",
    "\n",
    "nrows = ds.dset_id.size\n",
    "ncols = ds.season.size\n",
    "\n",
    "aspect = ds.cf.dims[\"Y\"] / ds.cf.dims[\"X\"]\n",
    "print(f\"aspect: {aspect}\")\n",
    "# ds = diffs.where(~diffs.isnull(), drop=True)\n",
    "tas = ds.tas\n",
    "# pole = ds.cf[\"grid_mapping\"]\n",
    "# transform = ccrs.RotatedPole(\n",
    "#    pole_latitude=pole.grid_north_pole_latitude,\n",
    "#    pole_longitude=pole.grid_north_pole_longitude,\n",
    "# )\n",
    "transform = ccrs.RotatedPole(pole_latitude=39.25, pole_longitude=-162.0)\n",
    "projection = transform\n",
    "\n",
    "# Define the figure and each axis for the 3 rows and 3 columns\n",
    "fig, axs = plt.subplots(\n",
    "    nrows=nrows,\n",
    "    ncols=ncols,\n",
    "    subplot_kw={\"projection\": projection},\n",
    "    figsize=(18, 18 * 1.05 * nrows / ncols),\n",
    "    sharex=True,\n",
    "    sharey=True,\n",
    "    gridspec_kw={\"wspace\": 0, \"hspace\": 0},\n",
    "    #  aspect_ratio=0.97,\n",
    ")\n",
    "\n",
    "# plt.subplots_adjust(wspace=0, hspace=0)\n",
    "\n",
    "# axs is a 2 dimensional array of `GeoAxes`.  We will flatten it into a 1-D array\n",
    "axs = axs.flatten()\n",
    "\n",
    "# Loop over all of the models\n",
    "for i, season in enumerate(ds.season.values):\n",
    "    for j, dset_id in enumerate(ds.dset_id.values):\n",
    "        pos = i + j * ncols\n",
    "        print(i, j, pos, season, dset_id)\n",
    "        # Select the week 1 forecast from the specified model\n",
    "        data = ds.tas.isel(season=i, dset_id=j)\n",
    "\n",
    "        # Add the cyclic point\n",
    "        # data,lons=add_cyclic_point(data,coord=ds['lon'])\n",
    "\n",
    "        # Contour plot\n",
    "        cs = axs[pos].contourf(\n",
    "            ds.cf[\"X\"],\n",
    "            ds.cf[\"Y\"],\n",
    "            data,\n",
    "            transform=transform,\n",
    "            # Define the levels for contourf\n",
    "            levels=np.arange(-8, 9, 1),\n",
    "            # cmap=\"coolwarm\",\n",
    "            extend=\"both\",\n",
    "            # vmin=-8, vmax=8,\n",
    "            cmap=\"RdBu_r\",\n",
    "        )\n",
    "\n",
    "        # if i == 3:\n",
    "        #    axs[pos].set_ylabel(dset_id)\n",
    "\n",
    "        axs[pos].set_aspect(round(aspect, 3))\n",
    "\n",
    "        # Title each subplot with the name of the model\n",
    "        # axs[pos].set_title(pos)\n",
    "\n",
    "        # Draw the coastines for each subplot\n",
    "        axs[pos].coastlines(resolution=\"50m\", color=\"black\", linewidth=0.5)\n",
    "\n",
    "        gl = axs[pos].gridlines(\n",
    "            draw_labels=False,\n",
    "            linewidth=0.3,\n",
    "            color=\"gray\",\n",
    "            xlocs=range(-180, 180, 10),\n",
    "            ylocs=range(-90, 90, 10),\n",
    "        )\n",
    "\n",
    "        # axs[pos].xaxis.set_tick_position('bottom')\n",
    "        # axs[pos].yaxis.set_tick_position('left')\n",
    "\n",
    "        # Longitude labels\n",
    "        # https://stackoverflow.com/questions/35479508/cartopy-set-xlabel-set-ylabel-not-ticklabels\n",
    "        if i == 3:\n",
    "            axs[pos].text(\n",
    "                1.1,\n",
    "                0.55,\n",
    "                dset_id,\n",
    "                va=\"bottom\",\n",
    "                ha=\"center\",\n",
    "                rotation=\"vertical\",\n",
    "                rotation_mode=\"anchor\",\n",
    "                transform=axs[pos].transAxes,\n",
    "            )\n",
    "        if j == 0:\n",
    "            axs[pos].text(\n",
    "                0.55,\n",
    "                1.05,\n",
    "                season,\n",
    "                va=\"bottom\",\n",
    "                ha=\"center\",\n",
    "                rotation=\"horizontal\",\n",
    "                rotation_mode=\"anchor\",\n",
    "                transform=axs[pos].transAxes,\n",
    "            )\n",
    "        # if i == 0:\n",
    "        # axs[pos].set_title(season)\n",
    "        #    axs[pos].set_xlabel(dset_id)\n",
    "        #    axs[pos].set_xticks(range(-180, 180, 10), crs=ccrs.PlateCarree())\n",
    "        # lon_formatter = cticker.LongitudeFormatter()\n",
    "        # axs[i].xaxis.set_major_formatter(lon_formatter)\n",
    "        lon_formatter = LongitudeFormatter(zero_direction_label=True)\n",
    "        lat_formatter = LatitudeFormatter()\n",
    "        axs[pos].xaxis.set_major_formatter(lon_formatter)\n",
    "        axs[pos].yaxis.set_major_formatter(lat_formatter)\n",
    "\n",
    "        # # Latitude labels\n",
    "        # axs[pos].set_yticks(range(-90, 90, 10), crs=ccrs.PlateCarree())\n",
    "        # lat_formatter = cticker.LatitudeFormatter()\n",
    "        # axs[i].yaxis.set_major_formatter(lat_formatter)\n",
    "\n",
    "# plt.subplots_adjust(wspace=0, hspace=0)\n",
    "\n",
    "# Adjust the location of the subplots on the page to make room for the colorbar\n",
    "# fig.subplots_adjust(bottom=0.1, top=0.9, left=0.1, right=0.9, wspace=0.08, hspace=0.08)\n",
    "\n",
    "# Add a colorbar axis at the bottom of the graph\n",
    "cbar_ax = fig.add_axes([0.2, 0.05, 0.6, 0.02])\n",
    "\n",
    "# Draw the colorbar\n",
    "cbar = fig.colorbar(cs, cax=cbar_ax, orientation=\"horizontal\")\n",
    "\n",
    "# Add a big title at the top\n",
    "# plt.suptitle('SubX Week 1 2m Temperature Anomalies ($^\\circ$C): Apr 16, 2020 Initialized Forecasts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
